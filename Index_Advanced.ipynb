{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<html>\n",
    "<p style=\"font-size:32px\"><strong>Classical Machine Learning</strong></p>\n",
    "</html>\n",
    "\n",
    "<html>\n",
    "<p style=\"font-size:26px\"><strong>Week 0</strong></p>\n",
    "</html>\n",
    " \n",
    "\n",
    "**Plan**\n",
    "- Setting up your learning and programming environment\n",
    "\n",
    "\n",
    "**Getting started**\n",
    "- [Setting up your ML environment](Setup_NYU.ipynb)\n",
    "    - [Choosing an ML environment](Choosing_an_ML_Environment_NYU.ipynb)\n",
    "- [Quick intro to the tools](Getting_Started.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 1\n",
    "\n",
    "**Plan**\n",
    "\n",
    "We give a brief introduction to the course.\n",
    "\n",
    "We then present the key concepts that form the basis for this course\n",
    "- For some: this will be review\n",
    "\n",
    "\n",
    "## Intro to Advanced Course\n",
    "\n",
    "- [Introduction to Advanced Course](Intro_Advanced.ipynb)\n",
    "\n",
    "Here is a *quick reference* of key concepts/notations from the Intro course\n",
    "- For some: it will be a review, for others: it will be a preview.  \n",
    "- We will devote a sub-module of this lecture to elaborate on each topic in slightly more depth.\n",
    "    - For a more detailed explanation: please refer to the material from the Intro course ([repo](https://github.com/kenperry-public/ML_Spring_2023))\n",
    "    \n",
    "- [Review and Preview](Review_Advanced.ipynb)\n",
    "\n",
    "\n",
    "You may want to run your code on Google Colab in order to take advantage of powerful GPU's.\n",
    "\n",
    "Here are some useful tips:\n",
    "\n",
    "[Google Colab tricks](Colab_practical.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Review/Preview of concepts from Intro Course\n",
    "\n",
    "### Transformers: Review\n",
    "\n",
    "**Preview**\n",
    "\n",
    "There is lots of interest in Large Language Models (e.g., ChatGPT).  These are based on an architecture called the Transformer.  We will introduce the Transformer and demonstrate some amazing results achieved by using Transformers to create Large Language Models.\n",
    "\n",
    "Attention is a mechanism that is a core part of the Transformer.  We will begin by first introducing Attention.\n",
    "\n",
    "We will then take a detour and study the Functional model architecture of Keras.  Unlike the Sequential model, which is an ordered sequence of Layers, the organization of blocks in a Functional model is more general.  The Advanced architectures (e.g., the Transformer) are built using the Functional model.\n",
    "\n",
    "Once we understand the technical prerequisites, we will examine the code for the Transformer.\n",
    "\n",
    "[Transformers: Review](Review_Transformer.ipynb)\n",
    "\n",
    "**Suggested reading**\n",
    "- Attention\n",
    "    - [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)  \n",
    "- Transfer Learning    \n",
    "    - [Sebastian Ruder: Transfer Learning](https://ruder.io/transfer-learning/)\n",
    "    \n",
    "**Further reading**\n",
    "- Attention\n",
    "    - [Neural Machine Translation by Jointly Learning To Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "    - Geron Chapter 16\n",
    "    - [An Analysis of BERT's Attention](https://arxiv.org/pdf/1906.04341.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 2: Review/Preview (continued); Technical\n",
    "\n",
    "\n",
    "**Plan**\n",
    "\n",
    "We continue the review/preview of key concepts that we started last week.\n",
    "\n",
    "Our ultimate goal is to introduce the Transformer (which uses Attention heavily) in theory, and demonstrate its use in Large Language Models.\n",
    "\n",
    "## Review/preview continued\n",
    "\n",
    "\n",
    "### [Transformer motivation: Illustrated](Attention_motivation_illustrated.ipynb)\n",
    "\n",
    "### [Transformer: flavors](Transformer.ipynb#Transformer:-Decoder)\n",
    "\n",
    "\n",
    "### Attention: in depth\n",
    "\n",
    "- [Implementing Attention](Attention_Lookup.ipynb)\n",
    "\n",
    "### [Transfer Learning: Review ](Review_TransferLearning.ipynb)\n",
    "\n",
    "### [Natural Language Processing: Review](Review_NLP.ipynb)\n",
    "\n",
    "### [LLM: Review](Review_LLM.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Functional Models\n",
    "\n",
    "**Plan**\n",
    "\n",
    "Enough theory (for the moment) !\n",
    "\n",
    "The Transformer (whose theory we have presented) is built from plain Keras.\n",
    "\n",
    "Our goal is to dig into the **code** for the Transformer so that you too will learn how to build advanced models.\n",
    "\n",
    "Before we can do this, we must\n",
    "- go beyond the Sequential model of Keras: introduction to the Functional model\n",
    "- understand more \"advanced\" features of Keras: customomizing layers,  training loops, loss functions\n",
    "- The Datasets API\n",
    "\n",
    "**Basics**\n",
    "\n",
    "We start with the basics of Functional models, and will give a coding example of such a model in Finance.\n",
    "\n",
    "- [Functional API](Functional_Models.ipynb)\n",
    "\n",
    "\n",
    "### Functional Model Code:  A Functional model in Finance: \"Factor model\"\n",
    "\n",
    "We illustrate the basic features of Functional models with an example\n",
    "- does not use the additional techniques of the next section (Advanced Keras)\n",
    "\n",
    "[Autoencoders for Conditional Risk Factors](Autoencoder_for_conditional_risk_factors.ipynb)\n",
    "- [code](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/20_autoencoders_for_conditional_risk_factors/06_conditional_autoencoder_for_asset_pricing_model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 3\n",
    "\n",
    "**Plan**\n",
    "\n",
    "We continue our study of Functional Models, introducing Advanced capabilities of Keras.\n",
    "\n",
    "## Functional Models (continued)\n",
    "\n",
    "- [Functional API (continued)](Functional_Models.ipynb#Gradient-Ascent)\n",
    "\n",
    "### Functional Model Code:  A Functional model in Finance: \"Factor model\"\n",
    "\n",
    "We illustrate the basic features of Functional models with an example\n",
    "- does not use the additional techniques of the next section (Advanced Keras)\n",
    "\n",
    "[Autoencoders for Conditional Risk Factors](Autoencoder_for_conditional_risk_factors.ipynb)\n",
    "- [code](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/20_autoencoders_for_conditional_risk_factors/06_conditional_autoencoder_for_asset_pricing_model.ipynb)\n",
    "\n",
    "### Threading\n",
    "\n",
    "In our [Autoencoders for Conditional Risk Factors](Autoencoder_for_conditional_risk_factors.ipynb), we skipped over an important detail\n",
    "- the \"Beta\" side of the notebook takes as input a matrix rather than a vector\n",
    "- how does a `Dense` layer work on higher dimensional data ?\n",
    "\n",
    "The answer is similar to how Python works:  [Threading](Keras_Advanced.ipynb#Factor-Models-and-Autoencoders:-Threading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Putting it all together: Code: the Transformer (continued)\n",
    "\n",
    "**Plan**\n",
    "\n",
    "With the base of advanced Keras under our belts, it's time to understand the Transformer, in code\n",
    "\n",
    "We will examine the code in the excellent [TensorFlow tutorial on the Transformer](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "- more in-depth than our presentation\n",
    "- more background\n",
    "\n",
    "The tutorial is especially recommended for those without the basics of the Transformer from my Intro course\n",
    "\n",
    "- [The Transformer: Understanding the Pieces](Transformer_Understanding_the_Pieces.ipynb)\n",
    "- [The Transformer: Code](Transformer_code.ipynb)\n",
    "- [Implementing Attention: detail](Implementing_Attention.ipynb)\n",
    "- [Choosing a Transformer architecture](Transformer_Choosing_a_PreTrained_Model.ipynb)\n",
    "\n",
    "**Suggested reading**\n",
    "\n",
    "There is an excellent tutorial on Attention and the Transformer which I recommend:\n",
    "- [Tensorflow tutorial: Neural machine translation with a Transformer and Keras](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "\n",
    "\n",
    "**Deeper dive**\n",
    "- [Implementing Attention](Attention_Lookup.ipynb)\n",
    "- [Residual connections](RNN_Residual_Networks.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advanced Keras (Deeper dive)\n",
    "\n",
    "We will not cover this [notebook](Keras_Advanced.ipynb) in class\n",
    "- most of the material will be introduced as part of our study of different interesting models\n",
    "- but this notebook is one convenient place to see them all\n",
    "- consider it as a **reference** that collects multiple techniques in one place\n",
    "\n",
    "**Deeper dives**\n",
    "\n",
    "If you *really* want to dig into the micro-details of TensorFlow, here are some important subtleties\n",
    "- [Computation Graphs](Computation_Graphs.ipynb)\n",
    "- [Eager vs Graph Execution](TF_Graph.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond Transfer Learning: Fine-tuning a pre-trained model\n",
    "\n",
    "**Plan**\n",
    "\n",
    "We begin the \"technical\" part of the course: the programming tools that will enable the Course Project.\n",
    "\n",
    "We introduce \"Modern Transfer Learning\": using model hubs.\n",
    "\n",
    "The hub we will use for the final project: HuggingFace\n",
    "- illustrate how to fine-tune a pre-trained model\n",
    "- quick Intro to HF\n",
    "    - best way to learn: through the course !\n",
    "    - uses Datasets\n",
    "        - will introduce later\n",
    "    - PyTorch version (uses Trainer); we will focus on Tensorflow/Keras version\n",
    "\n",
    "**HuggingFace Transformers course**\n",
    "\n",
    "The best way to understand and use modern Transfer Learning is via\n",
    "the [HuggingFace course](https://huggingface.co/course).\n",
    "\n",
    "You will learn\n",
    "- about the Transformer\n",
    "- how to use HuggingFace's tools for NLP (e.g., Tokenizers)\n",
    "- how to perform common NLP tasks\n",
    "    - especially with Transformers\n",
    "- how to fine-tune a pre-trained model\n",
    "- how to use the HuggingFace dataset API\n",
    "\n",
    "All of this will be invaluable for the Course Project.\n",
    "- does not have to be done using HuggingFace\n",
    "- but using at least parts of it will make your task easier\n",
    "\n",
    "\n",
    "- [HuggingFace intro](Transfer_Learning_HF.ipynb)\n",
    "    - [linked notebook: Using a pretrained Sequence Classifier](HF_quick_intro_to_models.ipynb) **(local machine)**\n",
    "    - [linked notebook: Using a pretrained Sequence Classifier](https://colab.research.google.com/github/kenperry-public/ML_Advanced_Fall_2024/blob/master/HF_quick_intro_to_models.ipynb) **(Google Colab)**\n",
    "        - Examining a model\n",
    "\n",
    "**Suggested reading**\n",
    "\n",
    "[HuggingFace course](https://huggingface.co/course)\n",
    "- you are well-advised to follow this material over the next 3 weeks in preparation for the Course Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 4\n",
    "\n",
    "## Inspecting a HuggingFace model from within Jupyter\n",
    "\n",
    "You don't need access to the source code ! You can inspect a model solely within Jupyter.\n",
    "\n",
    "<!--- #include (HF_quick_intro_to_models.ipynb)) --->\n",
    "\n",
    "- [linked notebook: Using a pretrained Sequence Classifier](https://colab.research.google.com/github/kenperry-public/ML_Advanced_Fall_2024/blob/master/HF_quick_intro_to_models.ipynb) **(Google Colab)**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Functional Model Code:  A Functional model in Finance: \"Factor model\"\n",
    "\n",
    "We illustrate the basic features of Functional models with an example\n",
    "- does not use the additional techniques of the next section (Advanced Keras)\n",
    "\n",
    "[Autoencoders for Conditional Risk Factors](Autoencoder_for_conditional_risk_factors.ipynb)\n",
    "- [code](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/20_autoencoders_for_conditional_risk_factors/06_conditional_autoencoder_for_asset_pricing_model.ipynb)\n",
    "\n",
    "### Threading\n",
    "\n",
    "In our [Autoencoders for Conditional Risk Factors](Autoencoder_for_conditional_risk_factors.ipynb), we skipped over an important detail\n",
    "- the \"Beta\" side of the notebook takes as input a matrix rather than a vector\n",
    "- how does a `Dense` layer work on higher dimensional data ?\n",
    "\n",
    "The answer is similar to how Python works:  [Threading](Keras_Advanced.ipynb#Factor-Models-and-Autoencoders:-Threading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers advanced: Scaling\n",
    "\n",
    "We now have the capabilities to build models with extremely large number of weights.\n",
    "Is it possible to have too many weights ? \n",
    "\n",
    "Yes: weights, number of training examples and compute capacity\n",
    "combine to determine the performance of a model.\n",
    "\n",
    "There is an empirical result that suggests that in order to take advantage of GPT-3's use of 175 billion weights\n",
    "- 1000 times more compute is required than what was used\n",
    "- 10 times more training examples is required compared to what was used\n",
    "\n",
    "Here is a view of the historical evolution of model sizes, and what the future might hold\n",
    "- [Large Language Model sizes: GPT history](NLP_Large_Language_Models.ipynb)\n",
    "- [How large should my Transformer be ?](Transformers_Scaling.ipynb)\n",
    "\n",
    "**Suggested reading**\n",
    "- [Scaling laws](https://arxiv.org/pdf/2001.08361.pdf)\n",
    "\n",
    "**Further reading**\n",
    "- Inference budget\n",
    "    - [Transformer Inference Arithmetic](https://kipp.ly/transformer-inference-arithmetic/)\n",
    "    - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf)\n",
    "    - [Large language models aren't trained enough](https://finbarr.ca/llms-not-trained-enough/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topics in Fine Tuning (Transfer Learning)\n",
    "\n",
    "## Fine Tuning at low cost\n",
    "\n",
    "### Parameter Efficient Transfer Learning\n",
    "\n",
    "Transfer learning may be the \"future of Deep Learning\" in that we can adapt models (that are too big for us to train on our own) to our own tasks.\n",
    "\n",
    "But Fine-Tuning a Pre-Trained model involves training a lot of parameters when the base model is large.\n",
    "\n",
    "This may be difficult for a variety of reasons.\n",
    "\n",
    "Can we adapt a Pre-Trained base model to a new task *without* training a large number of parameters ?\n",
    "\n",
    "- [Parameter Efficient Transfer Learning](ParameterEfficient_TransferLearning.ipynb)\n",
    "\n",
    "**Suggested reading**\n",
    "\n",
    "- [Parameter Efficient Transfer Learning - article](https://lightning.ai/pages/community/article/understanding-llama-adapters/)\n",
    "- [LoRA:Low Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)\n",
    "\n",
    "- Adapters\n",
    "    - [Parameter Efficient Transfer Learning for NLP](https://arxiv.org/pdf/1902.00751.pdf)\n",
    "    - [LLM Adapters](https://arxiv.org/pdf/2304.01933.pdf)\n",
    "\n",
    "**Additional reading**\n",
    "- [Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning](https://arxiv.org/abs/2012.13255)\n",
    "- [LoRA Learns Less and Forgets Less](https://arxiv.org/pdf/2405.09673)\n",
    "\n",
    "### Fine Tuning by Proxy\n",
    "\n",
    "Can we fine-tune a large model\n",
    "- **without** adapting its weights\n",
    "- by fine-tuning a **small** model\n",
    "    - much lower cost than fine-tuning a large model\n",
    "\n",
    "[Fine Tuning by Proxy](FineTuning_by_Proxy.ipynb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 5\n",
    "\n",
    "## Fine Tuning at low cost (continued)\n",
    "\n",
    "Rather than having one model for every task:\n",
    "- Is it possible to create a *single model* to solve every task ?\n",
    "\n",
    "Text to text is a \"Universal API\"\n",
    "- [Universal API](LLM_Universal_API.ipynb)\n",
    "\n",
    "### Fine Tuning by Prompt Engineering \n",
    "\n",
    "Given that an LLM can implement a Universal API\n",
    "\n",
    "- How do we create the *best* prompt to cause an LLM to solve a new \"target\" task ?\n",
    "\n",
    "\n",
    "- [Fine Tuning by Prompt Tuning](Prompt_Engineering_Tuning.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fine-Tuning \"**without** fine-tuning\" learning a new task from exemplars \n",
    "\n",
    "Building on the success of the Universal API\n",
    "- Using a clever prompt design to solve any task\n",
    "- Can we adapt a base LLM to solve a new Target task just by changing the prompt ?\n",
    "- *without* further training (Fine-Tuning)\n",
    "\n",
    "The answer is: yes !\n",
    "\n",
    "All we need to do is\n",
    "- show instances of examples for the new task *at inference time*\n",
    "- as part of the prompt\n",
    "- and the base model will \"learn\" to solve a new \"target\" task\n",
    "\n",
    "This is called *In-Context Learning*.\n",
    "\n",
    "[In-Context Learning](In_Context_Learning.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Datasets: Big data in small memory\n",
    "\n",
    "**Plan**\n",
    "\n",
    "The Dataset abstraction provides a way to consume large datasets using a limited amount of memory.\n",
    "\n",
    "We do a quick intro to HuggingFace datasets and how to use them with TensorFlow.\n",
    "\n",
    "We subsequently\n",
    "introduce the TensorFlow Dataset (TFDS) API.\n",
    "\n",
    "This is the last piece of technical info to enable the Final Project.\n",
    "\n",
    "**Background**\n",
    "- [Python generators](Generators.ipynb)\n",
    "\n",
    "**HuggingFace Datasets**\n",
    "\n",
    "- how to use a Dataset\n",
    "- using a HuggingFace dataset with Tensorflow\n",
    "\n",
    "[HuggingFace datasets in action](https://huggingface.co/learn/nlp-course/chapter3/2?fw=tf)\n",
    "\n",
    "\n",
    "**TensorFlow Dataset (TFDS)**\n",
    "\n",
    "\n",
    "- [TensorFlow Dataset](TF_Data_API.ipynb)\n",
    "\n",
    "\n",
    "**Notebooks**\n",
    "- [Dataset API: play around](TFDatasets_play_v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topics in Synthetic Data\n",
    "\n",
    "New major topic: Synthetic data.\n",
    "\n",
    "After last week's \"code-heavy\" modules, we are back to \"theory\" !\n",
    "\n",
    "We will address several ways to create new examples, starting with the simplest model and moving on to models that are more complex.\n",
    "\n",
    "We wrap up by demonstrating a new trend\n",
    "- using Large Language Models\n",
    "- to create training data\n",
    "- to improve Large Language Models !\n",
    "\n",
    "### Synthetic Data: Autoencoders\n",
    "\n",
    "Generating synthetic data using Autoencoders and its variants.\n",
    "\n",
    "#### \"Vanilla\" Autoencoder\n",
    "\n",
    "[Autoencoder](Autoencoders_Generative.ipynb)\n",
    "\n",
    "**Suggested Reading**\n",
    "\n",
    "[TensorFlow Tutorial on Autoencoders](https://www.tensorflow.org/tutorials/generative/autoencoder)\n",
    "\n",
    "\n",
    "#### Variational Autoencoder (VAE)\n",
    "\n",
    "\n",
    "We now study a different type of Autoencoder\n",
    "- that learns a *distribution* over the training examples\n",
    "- by sampling from this distribution: we can create synthetic examples\n",
    "\n",
    "[Variational Autoeconder (VAE)](VAE_Generative.ipynb)\n",
    "\n",
    "**Suggested Reading**\n",
    "\n",
    "[TensorFlow tutorial on VAE](https://www.tensorflow.org/tutorials/generative/cvae)\n",
    "\n",
    "**Further reading**\n",
    "\n",
    "[Tutorial on VAE](https://arxiv.org/pdf/1606.05908.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Synthetic Data: GANs\n",
    "\n",
    "We introduce a new type of model that can be used to generate synthetic data: the Generative Adversarial Network (GAN).  It uses a competitive process involving two Neural Networks in order to iteratively\n",
    "produce synthetic examples of increasing fidelity to the true data.\n",
    "\n",
    "- [GAN: basic](GAN_Generative.ipynb)\n",
    "- [GAN loss](GAN_Loss_Generative.ipynb)\n",
    "- [Wasserstein GAN](Wasserstein_GAN_Generative.ipynb)\n",
    "\n",
    "**Notebooks**\n",
    "- [GAN to Generate Faces](CelebA_01_deep_convolutional_generative_adversarial_network.ipynb)\n",
    "    \n",
    "**Suggested reading**\n",
    "- [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "- [TensorFlow Tutorial DCGAN](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb)\n",
    "    - this is a tutorial from which our code notebook was derived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 6\n",
    "\n",
    "## Topics in Synthetic Data (continued)\n",
    "\n",
    "### Synthetic Data: GANs (continued)\n",
    "\n",
    "- [GAN basic (continued): Loss and Training](http://localhost:8888/notebooks/NYU/GAN_Generative.ipynb#Loss-functions)\n",
    "\n",
    "- [GAN loss](GAN_Loss_Generative.ipynb)\n",
    "- [Wasserstein GAN](Wasserstein_GAN_Generative.ipynb)\n",
    "\n",
    "**Notebooks**\n",
    "- [GAN to Generate Faces](CelebA_01_deep_convolutional_generative_adversarial_network.ipynb)\n",
    "    \n",
    "**Suggested reading**\n",
    "- [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "- [TensorFlow Tutorial DCGAN](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb)\n",
    "    - this is a tutorial from which our code notebook was derived\n",
    "    \n",
    "### Synthetic Data: Self-improvement of an LLM by generating examples \n",
    "\n",
    "Text data for training an LLM is a precious commodity.\n",
    "\n",
    "We present a way \n",
    "- of synthesizing text examples to improve a Large Language Model\n",
    "- by using an existing LLM to synthesize new training examples !\n",
    "\n",
    "We illustrate how to create examples to train an LLM to exhibit Instruction Following behavior.\n",
    "- [LLM Instruction Following](LLM_Instruction_Following.ipynb)\n",
    "- [Synthetic data for Instruction Following](LLM_Instruction_Following_Synthetic_Data.ipynb)\n",
    "\n",
    "**Suggested Reading**\n",
    "\n",
    "- [InstructGPT paper](https://arxiv.org/pdf/2203.02155.pdf)\n",
    "- [Self-instruct](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "- [Self improvement](https://arxiv.org/pdf/2210.11610.pdf)\n",
    "    - goal is to fine-tune a LLM for question answering\n",
    "        - without an **a priori** fine-tuning dataset\n",
    "   - use a LLM to **generate** a fine-tuning dataset\n",
    "       - Use few-shot, CoT prompts: \n",
    "           - Input=question; Output=answer + rationale\n",
    "           - Input=question, LLM generates output\n",
    "               - multiple outputs\n",
    "               - extract answer from output\n",
    "                   - use majority voting on answer to filter responses\n",
    "                   - hopefully: majority is accurate: \"high confidence\" == fraction of responses that agree ?\n",
    "       - The high confidence (large fraction of generated responses to a question agree in answer) generated examples become the fine-tuning dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Topic: Multi-modal LLM's\n",
    "\n",
    "Large Language Models were originally conceived to process Language (sequences of tokens of Natural Language).\n",
    "\n",
    "But there is also interest in AI Assistants being able to handle *other types* of data\n",
    "- image\n",
    "- video\n",
    "-audio\n",
    "\n",
    "Do we need new model types for these non-language data ?\n",
    "\n",
    "We show how to adapt a Large Language Model (LLM) to understand (and generate) images.\n",
    "\n",
    "### Vector Quantized Autoencoders\n",
    "\n",
    "While we are on the topic of Autoencoders, we present the Vector Quantized Autoencoder. \n",
    "\n",
    "It is not so much a tool for creating Synthetic Data as a natural continuation of our Autoencoder exploration.\n",
    "\n",
    "[Vector Quantized Autoencoder](VQ_VAE_Generative.ipynb)\n",
    "\n",
    "**Suggested Reading**\n",
    "\n",
    "[vanilla VQ-VAE](https://arxiv.org/pdf/1711.00937.pdf)\n",
    "\n",
    "[VQ-VAE-2 paper](https://arxiv.org/pdf/1906.00446.pdf)\n",
    "\n",
    "### DALL-E: Mixing Text and Image\n",
    "\n",
    "We make use of the Quantized VAE technique we learned in the module on Autoencoders to enable us\n",
    "to mix text and image.  \n",
    "\n",
    "We discuss how a Text to Image model (convert the textual description of an image to an actual image) works.\n",
    "\n",
    "- [CLIP](CLIP.ipynb)\n",
    "    - [Zero shot learning, prompt engineering Colab notebook: PyTorch](https://github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb)\n",
    "- [DALL-E](DALL-E.ipynb)\n",
    "- [Vision Transformer](Vision_Transformer.ipynb)\n",
    "\n",
    "**Suggested Reading**\n",
    "- [CLIP paper](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)\n",
    "- [DALL-E paper](https://arxiv.org/pdf/2102.12092.pdf)\n",
    "\n",
    "- [OpenAI DALL-E 2 announcement](https://openai.com/dall-e-2/)\n",
    "- [Vision Transformer](https://arxiv.org/pdf/2010.11929.pdf)\n",
    "- [LiT paper](https://arxiv.org/pdf/2111.07991.pdf)\n",
    "\n",
    "### Contrastive Learning Objective\n",
    "\n",
    "CLiP used a Contrastive Learning Objective\n",
    "- find embeddings to \n",
    "    - maximize similarity between related examples (e.g., image and the text that describes it)\n",
    "    - minimize similarity between unrelated examples (e.g., image and text that *does not* describe it).\n",
    "\n",
    "CLiP used Binary Cross Entropy to meet the objective; we study a different approach.\n",
    "\n",
    "[Creating Embeddings for Similarity](Embeddings_similarity.ipynb)\n",
    "\n",
    "**Suggested Reading**\n",
    "\n",
    "- Triplet Loss: [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "- Sentence BERT: [entence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advanced Topics\n",
    "\n",
    "## In-Context Learning: Theory\n",
    "\n",
    "Why does In_Context Learning work ? Some theories.\n",
    "\n",
    "[In Context Learning: Theory](In_Context_Learning_Theory.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Additional Deep Learning resources\n",
    "\n",
    "Here are some resources that I have found very useful.\n",
    "\n",
    "Some of them are very nitty-gritty, deep-in-the-weeds (even the \"introductory\" courses)\n",
    "- For example: let's make believe PyTorch (or Keras/TensorFlow) didn't exists; let's invent Deep Learning without it !\n",
    "    - You will gain a deeper appreciation and understanding by re-inventing that which you take for granted\n",
    "    \n",
    "\n",
    "## [Andrej Karpathy course: Neural Networks, Zero to Hero](https://karpathy.ai/zero-to-hero.html)\n",
    "- PyTorch\n",
    "- Introductory, but at a very deep level of understanding\n",
    "    - you will get very deep into the weeds (hand-coding gradients !) but develop a deeper appreciation\n",
    "    \n",
    "## fast.ai\n",
    "\n",
    "`fast.ai` is a web-site with free courses from Jeremy Howard.\n",
    "- PyTorch\n",
    "- Introductory and courses \"for coders\"\n",
    "- Same courses offered every few years, but sufficiently different so as to make it worthwhile to repeat the course !\n",
    "    - [Practical Deep Learning](https://course.fast.ai/)\n",
    "    - [Stable diffusion](https://course.fast.ai/Lessons/part2.html)\n",
    "        - Very detailed, nitty-gritty details (like Karpathy) that will give you a deeper appreciation\n",
    "        \n",
    "## [Stefan Jansen: Machine Learning for Trading](https://github.com/stefan-jansen/machine-learning-for-trading)\n",
    "\n",
    "An excellent github repo with notebooks\n",
    "- using Deep Learning for trading\n",
    "- Keras\n",
    "- many notebooks are cleaner implementations of published models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignments\n",
    "\n",
    "Your assignments should follow the [Assignment Guidelines](assignments/Assignment_Guidelines.ipynb)\n",
    "\n",
    "## Final Project\n",
    "\n",
    "[Assignment notebook](assignments/FineTuning_HF/FineTune_FinancialPhraseBank.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
